{ 
    "paper_title" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
    "paper_url" :  "https://www.mdpi.com/1424-8220/22/19/7624",
    "paper_date" :   "10/2022",
    "tables" :  [ { 
        "title" : "",
        "rows" :  {
            "metrics" :  ["Precision", "Recall", "F1", "IoU", "Accuracy"],
            "datasets" :  "Inria Aerial Image Labeling",
            "subdataset" : "Train Val random split",
            "rows" :  [
                {
                    "model_name" : "UNet",
                    "model_fullname" : "" ,
                    "model_paper" : "U-net: Convolutional networks for biomedical image segmentation",
                    "paper_title" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_url" :  "https://www.mdpi.com/1424-8220/22/19/7624",
                    "paper_date" :   "10/2022",
                    "code_links" :  [""],
                    "model_links" :  [],
                    "metrics" :  {
                        "Precision" : 63.42,
                        "Recall": 75.79, 
                        "F1" : 63.77, 
                        "IoU": 51.29, 
                        "Accuracy" : 82.87} },
                {
                    "model_name" : "ResUNet",
                    "model_fullname" : "Residual UNet" ,
                    "model_paper" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_title" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_url" :  "https://www.mdpi.com/1424-8220/22/19/7624",
                    "paper_date" :   "10/2022",
                    "code_links" :  [""],
                    "model_links" :  [],
                    "metrics" :  {
                        "Precision" : 62.42,
                        "Recall": 68.08, 
                        "F1" : 60.57, 
                        "IoU": 47.74, 
                        "Accuracy" : 84.57} },
                {
                    "model_name" : "A-ResUNet",
                    "model_fullname" : "Attention Residial UNet" ,
                    "model_paper" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_title" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_url" :  "https://www.mdpi.com/1424-8220/22/19/7624",
                    "paper_date" :   "10/2022",
                    "code_links" :  [""],
                    "model_links" :  [],
                    "metrics" :  {
                        "Precision" : 62.52,
                        "Recall": 76.07, 
                        "F1" : 63.65, 
                        "IoU": 51.04, 
                        "Accuracy" : 83.59} },
                {
                    "model_name" : "Mobilenet UNet",
                    "model_fullname" : "Mobilenet UNet" ,
                    "model_paper" : "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_title" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_url" :  "https://www.mdpi.com/1424-8220/22/19/7624",
                    "paper_date" :   "10/2022",
                    "code_links" :  [""],
                    "model_links" :  [],
                    "metrics" :  {
                        "Precision" : 66.64,
                        "Recall": 64.06, 
                        "F1" : 57.63, 
                        "IoU": 44.52, 
                        "Accuracy" : 78.13} },
                {
                    "model_name" : "Inception UNet",
                    "model_fullname" : "Inception UNet" ,
                    "model_paper" : "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_title" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_url" :  "https://www.mdpi.com/1424-8220/22/19/7624",
                    "paper_date" :   "10/2022",
                    "code_links" :  [""],
                    "model_links" :  [],
                    "metrics" :  {
                        "Precision" : 66.64,
                        "Recall": 64.06, 
                        "F1" : 59.91, 
                        "IoU": 46.73, 
                        "Accuracy" : 84.75} },
                {
                    "model_name" : "Xception UNet",
                    "model_fullname" : "Xception UNet" ,
                    "model_paper" : "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_title" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_url" :  "https://www.mdpi.com/1424-8220/22/19/7624",
                    "paper_date" :   "10/2022",
                    "code_links" :  [""],
                    "model_links" :  [],
                    "metrics" :  {
                        "Precision" : 68.34,
                        "Recall": 71.00, 
                        "F1" : 64.86, 
                        "IoU": 52.10, 
                        "Accuracy" : 85.83} },
                {
                    "model_name" : "Incep-ResV2UNet",
                    "model_fullname" : "Incpetion Residual UNet" ,
                    "model_paper" : "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_title" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_url" :  "https://www.mdpi.com/1424-8220/22/19/7624",
                    "paper_date" :   "10/2022",
                    "code_links" :  [""],
                    "model_links" :  [],
                    "metrics" :  {
                        "Precision" : 64.81,
                        "Recall": 63.68, 
                        "F1" : 59.53, 
                        "IoU": 47.00, 
                        "Accuracy" : 85.50} },
                {
                    "model_name" : "TransUnet",
                    "model_fullname" : "TransUnet" ,
                    "model_paper" : "Transunet: Transformers make strong encoders for medical image segmentation",
                    "paper_title" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_url" :  "https://www.mdpi.com/1424-8220/22/19/7624",
                    "paper_date" :   "10/2022",
                    "code_links" :  [""],
                    "model_links" :  [],
                    "metrics" :  {
                        "Precision" : 67.42,
                        "Recall": 75.00, 
                        "F1" : 66.81, 
                        "IoU": 53.75, 
                        "Accuracy" : 89.65} },
                {
                    "model_name" : "SwinUnet",
                    "model_fullname" : "SwinUnet" ,
                    "model_paper" : "Swin-unet: Unet-like pure transformer for medical image segmentation",
                    "paper_title" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_url" :  "https://www.mdpi.com/1424-8220/22/19/7624",
                    "paper_date" :   "10/2022",
                    "code_links" :  [""],
                    "model_links" :  [],
                    "metrics" :  {
                        "Precision" : 75.10,
                        "Recall": 73.32, 
                        "F1" : 71.20, 
                        "IoU": 59.32, 
                        "Accuracy" : 89.65} },
                {
                    "model_name" : "RIUnet",
                    "model_fullname" : "RIUnet" ,
                    "paper_title" :  "A Residual-Inception U-Net (RIU-Net) Approach and Comparisons with U-Shaped CNN and Transformer Models for Building Segmentation from High-Resolution Satellite Images",
                    "paper_url" :  "https://www.mdpi.com/1424-8220/22/19/7624",
                    "paper_date" :   "10/2022",
                    "code_links" :  [""],
                    "model_links" :  [],
                    "metrics" :  {
                        "Precision" : 79.72,
                        "Recall": 80.50, 
                        "F1" : 78.68, 
                        "IoU": 67.36, 
                        "Accuracy" : 92.23} }
             ]
        } }
    ]
}